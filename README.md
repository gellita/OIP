**Команда:** Литвина Ангелина, Зиганшина Камила, 11-203

## Задания
- [Задание 1. Краулер для сайта ilibrary.ru (папка task1)](#задание-1)
- [Задание 2. Токены и леммы (папка task2)](#задание-2)

# Задание 1
# Краулер для сайта [ilibrary.ru](https://ilibrary.ru)

Программа автоматически:

- собирает ссылки на страницы текстов с сайта **ilibrary.ru**
- формирует файл `urls.txt` (список найденных страниц)
- скачивает минимум **100 HTML-страниц**
- сохраняет их **без очистки от HTML-разметки**
- создаёт файл `index.txt` (номер файла → URL)

HTML сохраняется полностью, в исходном виде.

---

## Требования

Для запуска необходимы:

- **Python 3.10** или выше
- установленный **pip**

---

## Установка зависимостей

Перед запуском установите необходимые библиотеки:

```bash
pip install requests beautifulsoup4 lxml
```

---

## Запуск программы

1. Откройте **терминал**.
2. Перейдите в папку проекта:
   ```bash
   cd путь_к_папке_проекта
   ```
3. Запустите скрипт:
   ```bash
   python crawler.py
   ```

После запуска программа автоматически:

- соберёт список ссылок;
- создаст файл `urls.txt`;
- скачает не менее 100 HTML-страниц;
- создаст папку `dump/` и сохранит туда страницы;
- сформирует файл `index.txt`, сопоставляющий локальные файлы с исходными URL.

---

# Задание 2

# Токены и леммы (папка task2)

Программа обрабатывает HTML-страницы, скачанные в **task1/dump**, и для **каждого файла** формирует:

* файл с **токенами** (уникальные слова после фильтрации)
* файл с **леммами** (нормальная форма слова → варианты словоформ)

Результаты сохраняются **по каждому входному файлу**:

* `task1/dump/1.txt` → `task2/tokens/tokens1.txt` и `task2/lemmas/lemmas1.txt`
* `task1/dump/2.txt` → `task2/tokens/tokens2.txt` и `task2/lemmas/lemmas2.txt`
* и т.д.

---

## Требования

Для запуска необходимы:

* **Python 3.10** или выше
* установленный **pip**

---

## Установка зависимостей

Перед запуском установите необходимые библиотеки:

```bash
pip install beautifulsoup4 lxml pymorphy3
```

---

## Запуск программы

1. Откройте **терминал**.
2. Перейдите в папку проекта `task2`:

   ```bash
   cd путь_к_папке_проекта/task2
   ```
3. Запустите скрипт:

   ```bash
   python tokens_lemmas.py
   ```

После запуска программа автоматически:

* прочитает все файлы из `../task1/dump/`
* создаст папки `tokens/` и `lemmas/` (если их нет)
* сохранит результаты **для каждого файла отдельно**:

  * `tokens/tokens1.txt`, `lemmas/lemmas1.txt`
  * `tokens/tokens2.txt`, `lemmas/lemmas2.txt`
  * и т.д.

---

## Результаты

В папке `task2` будут созданы две директории:

* `tokens/` — список токенов (уникальные слова) по каждому файлу
* `lemmas/` — леммы и соответствующие им словоформы по каждому файлу

### Формат `tokens/tokensN.txt`

Один токен на строку:

```txt
автор
время
город
...
```

### Формат `lemmas/lemmasN.txt`

Одна строка = лемма и все токены, которые к ней относятся:

```txt
город город города городом
читать читать читает читали
...
```

---

## Примечания

* Обрабатываются файлы `*.txt` из папки `task1/dump/`.
